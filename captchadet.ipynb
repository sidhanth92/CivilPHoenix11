{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "great-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "innocent-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images found:  1040\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n",
      "Shape of image:  (50, 200, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_dir = Path(\"samples\")\n",
    "\n",
    "\n",
    "\n",
    "# Get list of all the images\n",
    "images = list(data_dir.glob(\"*.png\"))\n",
    "print(\"Number of images found: \", len(images))\n",
    "\n",
    "\n",
    "# Let's take a look at some samples first. \n",
    "# Always look at your data!\n",
    "sample_images = images[:4]\n",
    "\n",
    "_,ax = plt.subplots(2,2, figsize=(5,3))\n",
    "for i in range(4):\n",
    "    img = cv2.imread(str(sample_images[i]))\n",
    "    print(\"Shape of image: \", img.shape)\n",
    "    ax[i//2, i%2].imshow(img)\n",
    "    ax[i//2, i%2].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "obvious-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unqiue charcaters in the whole dataset:  19\n",
      "Maximum length of any captcha:  5\n",
      "Characters present:  ['2', '3', '4', '5', '6', '7', '8', 'b', 'c', 'd', 'e', 'f', 'g', 'm', 'n', 'p', 'w', 'x', 'y']\n",
      "Total number of samples in the dataset:  1040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>samples\\8xef7.png</td>\n",
       "      <td>8xef7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>samples\\wecfd.png</td>\n",
       "      <td>wecfd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>samples\\373gb.png</td>\n",
       "      <td>373gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>samples\\bgb48.png</td>\n",
       "      <td>bgb48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>samples\\be6np.png</td>\n",
       "      <td>be6np</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            img_path  label\n",
       "0  samples\\8xef7.png  8xef7\n",
       "1  samples\\wecfd.png  wecfd\n",
       "2  samples\\373gb.png  373gb\n",
       "3  samples\\bgb48.png  bgb48\n",
       "4  samples\\be6np.png  be6np"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = set()\n",
    "\n",
    "# A list to store the length of each captcha\n",
    "captcha_length = []\n",
    "\n",
    "# Store image-label info\n",
    "dataset = []\n",
    "\n",
    "# Iterate over the dataset and store the\n",
    "# information needed\n",
    "for img_path in images:\n",
    "    # 1. Get the label associated with each image\n",
    "    label = img_path.name.split(\".png\")[0]\n",
    "    # 2. Store the length of this cpatcha\n",
    "    captcha_length.append(len(label))\n",
    "    # 3. Store the image-label pair info\n",
    "    dataset.append((str(img_path), label))\n",
    "    \n",
    "    # 4. Store the characters present\n",
    "    for ch in label:\n",
    "        characters.add(ch)\n",
    "\n",
    "# Sort the characters        \n",
    "characters = sorted(characters)\n",
    "\n",
    "# Convert the dataset info into a dataframe\n",
    "dataset = pd.DataFrame(dataset, columns=[\"img_path\", \"label\"], index=None)\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"Number of unqiue charcaters in the whole dataset: \", len(characters))\n",
    "print(\"Maximum length of any captcha: \", max(Counter(captcha_length).keys()))\n",
    "print(\"Characters present: \", characters)\n",
    "print(\"Total number of samples in the dataset: \", len(dataset))\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuck-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  936\n",
      "Number of validation samples:  104\n",
      "Number of training images:  (936, 50, 200)\n",
      "Number of training labels:  (936,)\n",
      "Number of validation images:  (104, 50, 200)\n",
      "Number of validation labels:  (104,)\n"
     ]
    }
   ],
   "source": [
    "training_data, validation_data = train_test_split(dataset, test_size=0.1, random_state=seed)\n",
    "\n",
    "training_data = training_data.reset_index(drop=True)\n",
    "validation_data = validation_data.reset_index(drop=True)\n",
    "\n",
    "print(\"Number of training samples: \", len(training_data))\n",
    "print(\"Number of validation samples: \", len(validation_data))\n",
    "\n",
    "\n",
    "\n",
    "# Map text to numeric labels \n",
    "char_to_labels = {char:idx for idx, char in enumerate(characters)}\n",
    "\n",
    "# Map numeric labels to text\n",
    "labels_to_char = {val:key for key, val in char_to_labels.items()}\n",
    "\n",
    "\n",
    "\n",
    "# Sanity check for corrupted images\n",
    "def is_valid_captcha(captcha):\n",
    "    for ch in captcha:\n",
    "        if not ch in characters:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "\n",
    "# Store arrays in memory as it's not a muvh big dataset\n",
    "def generate_arrays(df, resize=True, img_height=50, img_width=200):\n",
    "    \"\"\"Generates image array and labels array from a dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: dataframe from which we want to read the data\n",
    "        resize (bool)    : whether to resize images or not\n",
    "        img_weidth (int): width of the resized images\n",
    "        img_height (int): height of the resized images\n",
    "        \n",
    "    Returns:\n",
    "        images (ndarray): grayscale images\n",
    "        labels (ndarray): corresponding encoded labels\n",
    "    \"\"\"\n",
    "    \n",
    "    num_items = len(df)\n",
    "    images = np.zeros((num_items, img_height, img_width), dtype=np.float32)\n",
    "    labels = [0]*num_items\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        img = cv2.imread(df[\"img_path\"][i])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if resize: \n",
    "            img = cv2.resize(img, (img_width, img_height))\n",
    "        \n",
    "        img = (img/255.).astype(np.float32)\n",
    "        label = df[\"label\"][i]\n",
    "        \n",
    "        # Add only if it is a valid captcha\n",
    "        if is_valid_captcha(label):\n",
    "            images[i, :, :] = img\n",
    "            labels[i] = label\n",
    "    \n",
    "    return images, np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "# Build training data\n",
    "training_data, training_labels = generate_arrays(df=training_data)\n",
    "print(\"Number of training images: \", training_data.shape)\n",
    "print(\"Number of training labels: \", training_labels.shape)\n",
    "\n",
    "\n",
    "# Build validation data\n",
    "validation_data, validation_labels = generate_arrays(df=validation_data)\n",
    "print(\"Number of validation images: \", validation_data.shape)\n",
    "print(\"Number of validation labels: \", validation_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "forward-standard",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"Generates batches from a given dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: training or validation data\n",
    "        labels: corresponding labels\n",
    "        char_map: dictionary mapping char to labels\n",
    "        batch_size: size of a single batch\n",
    "        img_width: width of the resized\n",
    "        img_height: height of the resized\n",
    "        downsample_factor: by what factor did the CNN downsample the images\n",
    "        max_length: maximum length of any captcha\n",
    "        shuffle: whether to shuffle data or not after each epoch\n",
    "    Returns:\n",
    "        batch_inputs: a dictionary containing batch inputs \n",
    "        batch_labels: a batch of corresponding labels \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 labels,\n",
    "                 char_map,\n",
    "                 batch_size=16,\n",
    "                 img_width=200,\n",
    "                 img_height=50,\n",
    "                 downsample_factor=4,\n",
    "                 max_length=5,\n",
    "                 shuffle=True\n",
    "                ):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.char_map = char_map\n",
    "        self.batch_size = batch_size\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.max_length = max_length\n",
    "        self.shuffle = shuffle\n",
    "        self.indices = np.arange(len(data))    \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Get the next batch indices\n",
    "        curr_batch_idx = self.indices[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        \n",
    "        # 2. This isn't necessary but it can help us save some memory\n",
    "        # as not all batches the last batch may not have elements\n",
    "        # equal to the batch_size \n",
    "        batch_len = len(curr_batch_idx)\n",
    "        \n",
    "        # 3. Instantiate batch arrays\n",
    "        batch_images = np.ones((batch_len, self.img_width, self.img_height, 1),\n",
    "                               dtype=np.float32)\n",
    "        batch_labels = np.ones((batch_len, self.max_length), dtype=np.float32)\n",
    "        input_length = np.ones((batch_len, 1), dtype=np.int64) * \\\n",
    "                                (self.img_width // self.downsample_factor - 2)\n",
    "        label_length = np.zeros((batch_len, 1), dtype=np.int64)\n",
    "        \n",
    "        \n",
    "        for j, idx in enumerate(curr_batch_idx):\n",
    "            # 1. Get the image and transpose it\n",
    "            img = self.data[idx].T\n",
    "            # 2. Add extra dimenison\n",
    "            img = np.expand_dims(img, axis=-1)\n",
    "            # 3. Get the correpsonding label\n",
    "            text = self.labels[idx]\n",
    "            # 4. Include the pair only if the captcha is valid\n",
    "            if is_valid_captcha(text):\n",
    "                label = [self.char_map[ch] for ch in text]\n",
    "                batch_images[j] = img\n",
    "                batch_labels[j] = label\n",
    "                label_length[j] = len(text)\n",
    "        \n",
    "        batch_inputs = {\n",
    "                'input_data': batch_images,\n",
    "                'input_label': batch_labels,\n",
    "                'input_length': input_length,\n",
    "                'label_length': label_length,\n",
    "                }\n",
    "        return batch_inputs, np.zeros(batch_len).astype(np.float32)\n",
    "        \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supported-outreach",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width=200\n",
    "img_height=50 \n",
    "\n",
    "# Factor  by which the image is going to be downsampled\n",
    "# by the convolutional blocks\n",
    "downsample_factor=4\n",
    "\n",
    "# Maximum length of any captcha in the data\n",
    "max_length=5\n",
    "\n",
    "# Get a generator object for the training data\n",
    "train_data_generator = DataGenerator(data=training_data,\n",
    "                                     labels=training_labels,\n",
    "                                     char_map=char_to_labels,\n",
    "                                     batch_size=batch_size,\n",
    "                                     img_width=img_width,\n",
    "                                     img_height=img_height,\n",
    "                                     downsample_factor=downsample_factor,\n",
    "                                     max_length=max_length,\n",
    "                                     shuffle=True\n",
    "                                    )\n",
    "\n",
    "# Get a generator object for the validation data \n",
    "valid_data_generator = DataGenerator(data=validation_data,\n",
    "                                     labels=validation_labels,\n",
    "                                     char_map=char_to_labels,\n",
    "                                     batch_size=batch_size,\n",
    "                                     img_width=img_width,\n",
    "                                     img_height=img_height,\n",
    "                                     downsample_factor=downsample_factor,\n",
    "                                     max_length=max_length,\n",
    "                                     shuffle=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "maritime-detroit",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred, input_length, label_length):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "        \n",
    "        # On test time, just return the computed loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    # Inputs to the model\n",
    "    input_img = layers.Input(shape=(img_width, img_height, 1),\n",
    "                            name='input_data',\n",
    "                            dtype='float32')\n",
    "    labels = layers.Input(name='input_label', shape=[max_length], dtype='float32')\n",
    "    input_length = layers.Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = layers.Input(name='label_length', shape=[1], dtype='int64')\n",
    "    \n",
    "    # First conv block\n",
    "    x = layers.Conv2D(32,\n",
    "               (3,3),\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv1')(input_img)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    # Second conv block\n",
    "    x = layers.Conv2D(64,\n",
    "               (3,3),\n",
    "               activation='relu',\n",
    "               kernel_initializer='he_normal',\n",
    "               padding='same',\n",
    "               name='Conv2')(x)\n",
    "    x = layers.MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    # We have used two max pool with pool size and strides of 2.\n",
    "    # Hence, downsampled feature maps are 4x smaller. The number of\n",
    "    # filters in the last layer is 64. Reshape accordingly before\n",
    "    # passing it to RNNs\n",
    "    new_shape = ((img_width // 4), (img_height // 4)*64)\n",
    "    x = layers.Reshape(target_shape=new_shape, name='reshape')(x)\n",
    "    x = layers.Dense(64, activation='relu', name='dense1')(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    # RNNs\n",
    "    x = layers.Bidirectional(layers.LSTM(128,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.2))(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(64,\n",
    "                                         return_sequences=True,\n",
    "                                         dropout=0.25))(x)\n",
    "    \n",
    "    # Predictions\n",
    "    x = layers.Dense(len(characters)+1,\n",
    "              activation='softmax', \n",
    "              name='dense2',\n",
    "              kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    # Calculate CTC\n",
    "    output = CTCLayer(name='ctc_loss')(labels, x, input_length, label_length)\n",
    "    \n",
    "    # Define the model\n",
    "    model = keras.models.Model(inputs=[input_img,\n",
    "                                       labels,\n",
    "                                       input_length,\n",
    "                                       label_length],\n",
    "                                outputs=output,\n",
    "                                name='ocr_model_v1')\n",
    "    \n",
    "    # Optimizer\n",
    "    sgd = keras.optimizers.SGD(learning_rate=0.002,\n",
    "                               decay=1e-6,\n",
    "                               momentum=0.9,\n",
    "                               nesterov=True,\n",
    "                               clipnorm=5)\n",
    "    \n",
    "    # Compile the model and return \n",
    "    model.compile(optimizer=sgd)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dirty-princeton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ocr_model_v1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         [(None, 200, 50, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 200, 50, 32)  320         input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 100, 25, 32)  0           Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv2 (Conv2D)                  (None, 100, 25, 64)  18496       pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 50, 12, 64)   0           Conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 768)      0           pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 50, 64)       49216       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 64)       0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 256)      197632      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 128)      164352      bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 50, 20)       2580        bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss (CTCLayer)             (None, 1)            0           input_label[0][0]                \n",
      "                                                                 dense2[0][0]                     \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 432,596\n",
      "Trainable params: 432,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "pediatric-mexican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 18s 191ms/step - loss: 40.5343 - val_loss: 16.4100\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 9s 150ms/step - loss: 16.4083 - val_loss: 16.4556\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 16.4122 - val_loss: 16.3852\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 9s 152ms/step - loss: 16.3502 - val_loss: 16.3357\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 16.2578 - val_loss: 16.1386\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 9s 157ms/step - loss: 16.1052 - val_loss: 16.1700\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 16.0042 - val_loss: 16.0446\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 15.9699 - val_loss: 16.0787\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 15.9177 - val_loss: 16.0696\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 15.8624 - val_loss: 15.6437\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 15.4881 - val_loss: 15.3900\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 15.0296 - val_loss: 14.9304\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 9s 152ms/step - loss: 14.6953 - val_loss: 14.5699\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 14.3851 - val_loss: 14.2459\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 13.9364 - val_loss: 13.8680\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 13.6683 - val_loss: 13.3570\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 13.2860 - val_loss: 13.1500\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 12.7694 - val_loss: 12.9643\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 12.4119 - val_loss: 12.2391\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 11.9909 - val_loss: 11.5143\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 9s 152ms/step - loss: 11.1559 - val_loss: 10.2713\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 9.9338 - val_loss: 8.5181\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 8.3108 - val_loss: 6.8462\n",
      "Epoch 24/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 6.7657 - val_loss: 5.4028\n",
      "Epoch 25/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 5.3112 - val_loss: 3.4418\n",
      "Epoch 26/50\n",
      "59/59 [==============================] - 9s 157ms/step - loss: 3.8783 - val_loss: 2.3606\n",
      "Epoch 27/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 2.6494 - val_loss: 1.5165\n",
      "Epoch 28/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 1.8689 - val_loss: 1.0228\n",
      "Epoch 29/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 1.4656 - val_loss: 0.8209\n",
      "Epoch 30/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 1.0159 - val_loss: 1.1339\n",
      "Epoch 31/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 0.9994 - val_loss: 0.7139\n",
      "Epoch 32/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.8711 - val_loss: 0.4992\n",
      "Epoch 33/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 0.6698 - val_loss: 0.3181\n",
      "Epoch 34/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 0.5576 - val_loss: 0.5010\n",
      "Epoch 35/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 0.5692 - val_loss: 0.1720\n",
      "Epoch 36/50\n",
      "59/59 [==============================] - 9s 155ms/step - loss: 0.4958 - val_loss: 0.1305\n",
      "Epoch 37/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.3734 - val_loss: 0.1586\n",
      "Epoch 38/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.2919 - val_loss: 0.1551\n",
      "Epoch 39/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 0.3065 - val_loss: 0.0761\n",
      "Epoch 40/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.2714 - val_loss: 0.0859\n",
      "Epoch 41/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.1849 - val_loss: 0.1405\n",
      "Epoch 42/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.1806 - val_loss: 0.0915\n",
      "Epoch 43/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 0.1564 - val_loss: 0.1353\n",
      "Epoch 44/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.1644 - val_loss: 0.0270\n",
      "Epoch 45/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 0.0850 - val_loss: 0.0712\n",
      "Epoch 46/50\n",
      "59/59 [==============================] - 9s 154ms/step - loss: 0.0961 - val_loss: 0.0273\n",
      "Epoch 47/50\n",
      "59/59 [==============================] - 9s 160ms/step - loss: 0.2418 - val_loss: 0.0223\n",
      "Epoch 48/50\n",
      "59/59 [==============================] - 9s 156ms/step - loss: 0.0854 - val_loss: 0.0423\n",
      "Epoch 49/50\n",
      "59/59 [==============================] - 9s 159ms/step - loss: 0.0762 - val_loss: 0.0310\n",
      "Epoch 50/50\n",
      "59/59 [==============================] - 9s 153ms/step - loss: 0.0822 - val_loss: 0.0303\n"
     ]
    }
   ],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                   patience=5,\n",
    "                                   restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data_generator,\n",
    "                    validation_data=valid_data_generator,\n",
    "                    epochs=50,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reverse-sierra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_data (InputLayer)      [(None, 200, 50, 1)]      0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv2D)               (None, 200, 50, 32)       320       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 100, 25, 32)       0         \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv2D)               (None, 100, 25, 64)       18496     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 50, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 50, 768)           0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 50, 64)            49216     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 50, 256)           197632    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 50, 128)           164352    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 50, 20)            2580      \n",
      "=================================================================\n",
      "Total params: 432,596\n",
      "Trainable params: 432,596\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction_model = keras.models.Model(model.get_layer(name='input_data').input,\n",
    "                                        model.get_layer(name='dense2').output)\n",
    "prediction_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sitting-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_batch_predictions(pred):\n",
    "    pred = pred[:, :-2]\n",
    "    input_len = np.ones(pred.shape[0])*pred.shape[1]\n",
    "    \n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, \n",
    "                                        input_length=input_len,\n",
    "                                        greedy=True)[0][0]\n",
    "    \n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results.numpy():\n",
    "        outstr = ''\n",
    "        for c in res:\n",
    "            if c < len(characters) and c >=0:\n",
    "                outstr += labels_to_char[c]\n",
    "        output_text.append(outstr)\n",
    "    \n",
    "    # return final text results\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exotic-lesson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth: bn5mw \t Predicted: bn5mw\n",
      "Ground truth: bdg84 \t Predicted: bdg84\n",
      "Ground truth: nfd8g \t Predicted: nfd8g\n",
      "Ground truth: 2g783 \t Predicted: 2g783\n",
      "Ground truth: 377xx \t Predicted: 377xx\n",
      "Ground truth: edwny \t Predicted: edwny\n",
      "Ground truth: ecd4w \t Predicted: ecd4w\n",
      "Ground truth: ec6pm \t Predicted: ec6pm\n",
      "Ground truth: dnmd8 \t Predicted: dnmd8\n",
      "Ground truth: 2en7g \t Predicted: 2en7g\n",
      "Ground truth: x5f54 \t Predicted: x5f54\n",
      "Ground truth: 6fg8c \t Predicted: 6fg8c\n",
      "Ground truth: p8wwf \t Predicted: p8wwf\n",
      "Ground truth: e5n66 \t Predicted: e5n66\n",
      "Ground truth: dbfen \t Predicted: dbfen\n",
      "Ground truth: 5dxnm \t Predicted: 5dxnm\n"
     ]
    }
   ],
   "source": [
    "for p, (inp_value, _) in enumerate(valid_data_generator):\n",
    "    bs = inp_value['input_data'].shape[0]\n",
    "    X_data = inp_value['input_data']\n",
    "    labels = inp_value['input_label']\n",
    "    \n",
    "    preds = prediction_model.predict(X_data)\n",
    "    pred_texts = decode_batch_predictions(preds)\n",
    "    \n",
    "    \n",
    "    orig_texts = []\n",
    "    for label in labels:\n",
    "        text = ''.join([labels_to_char[int(x)] for x in label])\n",
    "        orig_texts.append(text)\n",
    "        \n",
    "    for i in range(bs):\n",
    "        print(f'Ground truth: {orig_texts[i]} \\t Predicted: {pred_texts[i]}')\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-treasure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
